# Learning Language as AI

通过基本词汇的维基百科组成语料，供以学习语言和百科。

## 背景
通常说的词汇量是指词干数量。有的研究表明认识98%的文本才能基本理解句意。然而统计发现十万词（非词干）不足以覆盖英语98%。AI模型通常2^15=32768词表便已足够。所以尝试人类按照AI模型训练的办法学习。
筛选基本词汇，构建百科语料，学会语言和百科知识。
定义词汇等级=-lg(词频)

## 依赖工具
* Wiki2text:wikipedia解析器
* ZiTokenizer:分词器

## 语料
维基百科
Wiki2text解析wikipedia

## 词表
维基百科+维基古书
glance.py
统计词频 
等级五内,7k; 等级六内,33k
某些测试称需要几千词汇，是指圈定的几千词干。本项目的此表是频率筛选的绝对词表。

## 术语筛选策略
sample.py
抽取术语  
百科标题：标题=核心词，否则标题包含核心词。 1e-5,3k
词典：纯粹英文单词
交互筛选：剔除专有名词

## 百科筛选策略
选文：第一段，第一节，至少100个字。
匹配：提纲挈领，引领诸多更低频词。平常词1.5e-5~1.5e-6，5k~25k，去重平常词比例高者。

##  排版
等级六太大，仅仅输出等级五
条例
    标题
    正文
    术语
    "word","phonetic","definition","translation","root","lemma"，"degre"
